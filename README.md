# Team Name: Data Scouts
## Team Members:
 1) Sai Harika Paluri
 2) Nikhil Kumar Mutyala
 3) Sri Divya Keerthi Paravasthu Siddhanthi
 4) Ravi Theja Goalla
 5) Nivedita Veeramanigandan
 
#  Project Title:

## Project Description:

## Data:
We still didn't get our dataset, so we will update it in a few days.

# CRISP-DM Process:

Cross-industry standard process for data mining, known as CRISP-DM, is an open standard process model that describes common approaches used by data mining experts. It is the most widely-used analytics model.

![alt text](https://github.com/NikhilKumarMutyala/KDD-Project/blob/master/crisp%20dm.PNG)
*image credits: [Youtube](https://www.youtube.com/watch?v=CRKn-9gVNBw)*

This model is an idealised sequence of events. In practice many of the tasks can be performed in a different order and it will often be necessary to backtrack to previous tasks and repeat certain actions. The model does not try to capture all possible routes through the data mining process.
CRISP-DM breaks the process of data mining into six major phases:

* Business Understanding
* Data Understanding
* Data Preparation
* Modeling
* Evaluation
* Deployment

 ## Business Understanding

The first thing we must do in any project is to find out exactly what we are trying to accomplish. We must state objectives and requirements. We should translate these goals and restrictions into the formulation of a data mining problem definition. We must start with a clear understanding of

* A problem that you want to address/ Objectives

* The business goals

* Constraints

 Finally, we prepare a preliminary strategy for achieving these objectives.
 
 ## Data Understanding
 
 The second stage of the CRISP-DM process requires us to acquire the data listed in the project resources. This initial collection includes data loading, if this is necessary for data understanding. The data-understanding phase includes four tasks. These are

* Gathering data

* Describing data

* Exploring data

* Verifying data quality

### Gathering Data

We need to verify that we have acquired the data or at least gained access to the data, tested the data access process, and verified that the data exists. First we need to Outline data requirements, Verify data availability, Define selection criteria.

### Describing Data

We describe the source and formats of the data, the number of cases, the number and descriptions of the fields, and any other general information that may be important.

### Exploring Data

We look at the range of values and their distributions. We’ll use simple data manipulation and basic statistical techniques for further checks into the data. Data exploration supports several purposes:

* Get familiar with the data

* Spot signs of data quality problems

* Set the stage for data preparation steps

### Verifying Data  Quality

now we have to determine whether it’s good enough to support our goals. We will often have some quality problem to address yet still be able to move forward, but at times the data quality is so poor that it cannot support our plan and we’ll have to look for alternatives. 
